{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 47,
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "from math import *\n",
<<<<<<< HEAD
    "import numpy as np\n",
    "import copy\n",
    "import sys"
=======
    "import numpy as np"
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random dataset with some character to it - in this case the sum of n random numbers is similar to a normal distribution. The values range from 0 to 1, but the functions could work with whatever arbitrary range.\n",
    "\n",
    "This corresponds to the set of observations in a given week - so it could be hourly temperature measurements... perhaps 7 * 24 = 168 of them, or if there are data gaps then fewer."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 48,
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 168 #number of hours in a week\n",
    "rand_reps = 20\n",
    "test_floats = [sum([rand.random() for i in range(rand_reps)])/rand_reps for i in range(n)]\n",
    "#print(test_floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the way that the histogram is built. It is defined between a min and a max, and has a specific bin width. So if the minimum was 1, and the bin_width 0.5, any value between 1 and 1.5 would fall into the first bin, while values between 1.5 and 2 would fall into the second bin. If the maximum was 2.2, there would be three bins, the third could be thought of as ranging between 2 and 2.2, but effectively ranges from 2 to 2.5. Values exactly on a bin_boundary would be assigned to the upper bin, so 1.5 would be in the 1.5 to 2 bin.\n",
    "\n",
    "bin_boundaries are not actually used, just included for clarity. max is also not used - it's not prescriptive, except when determining how many bins to generate, and as alluded to above those could go higher than the max if the bin boundaries don't align with the max."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 65,
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03 0.0 1.0 [0.0, 0.03, 0.06, 0.09, 0.12, 0.15, 0.18, 0.21, 0.24, 0.27, 0.3, 0.32999999999999996, 0.36, 0.39, 0.42, 0.44999999999999996, 0.48, 0.51, 0.54, 0.57, 0.6, 0.63, 0.6599999999999999, 0.69, 0.72, 0.75, 0.78, 0.8099999999999999, 0.84, 0.87, 0.8999999999999999, 0.9299999999999999, 0.96, 0.99, 1.02]\n"
     ]
    }
   ],
   "source": [
    "bin_width = 0.03\n",
    "minimum = 0.0\n",
    "maximum = 1.0\n",
    "n_bins = int(ceil((maximum-minimum)/bin_width))\n",
    "bin_boundaries = [minimum+i*bin_width for i in range(n_bins+1)]\n",
    "print(bin_width, minimum, maximum, bin_boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a histogram data structure as a dictionary. Could be built object-oriented, but this is succinct in this context."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 66,
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_list = [0 for i in range(n_bins)] #Could be a numpy int array or something like that.\n",
    "hist_settings = {\n",
    "    \"bin_width\":bin_width,\n",
    "    \"minimum\":minimum,\n",
    "    \"maximum\":maximum,\n",
    "    \"n_bins\":n_bins,\n",
    "    \"bin_boundaries\":bin_boundaries,\n",
    "    \"histogram_list\":histogram_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the dataset and put it into the histogram - this is the critical \"pre-processing\" step that could be conducted at the time of download. Once this is done, the raw data theoretically doesn't need to be revisited. However, if we changed something like the bin-width, then it would have to be rerun.\n",
    "\n",
    "The number of bins we use is a critical decision with a tradeoff on accuracy vs. data. The raw data includes 168 floats. The histogram might include more like 20 char values (given there's only 168 hours in a week, we never have a count of more than 256 in a single histogram bin). So 32 * 168 = 5376 bits vs 8 * 20 = 160 bits means 1/30th the memory footprint. Note however that 20 bins may be a bit limiting, since the histogram probably needs to span all possible values for all station locations. So temperatures might run from -100 F to + 150 F. That's 12.5 F per bin, so if there's a week where the temperature waffles between 30 and 40, all the data would fall in one bin. Is that a problem? Maybe not - a simple triangle distribution may be enough detail. Also we could pick the minimum and bin-width so that a bin boundary lay exactly at freezing, since that's a sort of important number to caputre accurately. Put another way, if we had a bin-boundary at 32 F, and 12.5 F bins, we couldnt' tell the difference between 32 F and 44.4 F. We would in effect assume all temperatures in that range are 38.25 F.\n",
    "\n",
    "I don't think there's a problem assigning different numbers of bins to different parameters. Also we could apply some sort of transformation to vary precision, such as resolving fine differences in horizontal visibility in thick fog, but lumping together huge ranges for clear days (5 mile visibility isn't very different from 20 mile visibility, but 100 feet visibility is quite different from 500 feet.) To capture this possibility I included the optional transform function that can be passed to the populate function below, but to really use it the function needs to be more aware of what's going on - see object oriented version below."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 70,
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'bin_width': 0.03, 'minimum': 0.0, 'maximum': 1.0, 'n_bins': 34, 'bin_boundaries': [0.0, 0.03, 0.06, 0.09, 0.12, 0.15, 0.18, 0.21, 0.24, 0.27, 0.3, 0.32999999999999996, 0.36, 0.39, 0.42, 0.44999999999999996, 0.48, 0.51, 0.54, 0.57, 0.6, 0.63, 0.6599999999999999, 0.69, 0.72, 0.75, 0.78, 0.8099999999999999, 0.84, 0.87, 0.8999999999999999, 0.9299999999999999, 0.96, 0.99, 1.02], 'histogram_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 8, 21, 27, 25, 32, 20, 16, 12, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
=======
      "{'bin_width': 0.03, 'min': 0.0, 'max': 1.0, 'n_bins': 34, 'bin_boundaries': [0.0, 0.03, 0.06, 0.09, 0.12, 0.15, 0.18, 0.21, 0.24, 0.27, 0.3, 0.32999999999999996, 0.36, 0.39, 0.42, 0.44999999999999996, 0.48, 0.51, 0.54, 0.57, 0.6, 0.63, 0.6599999999999999, 0.69, 0.72, 0.75, 0.78, 0.8099999999999999, 0.84, 0.87, 0.8999999999999999, 0.9299999999999999, 0.96, 0.99, 1.02], 'histogram_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 18, 34, 64, 74, 48, 60, 16, 6, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
     ]
    }
   ],
   "source": [
    "def identity(value):\n",
    "    return value\n",
    "\n",
    "def populate_histogram(data, bin_width, minimum, maximum, n_bins, bin_boundaries, histogram_list, transform = identity):\n",
    "    for value in data:\n",
    "        value = transform(value)\n",
    "        if value < minimum: list_index = 0\n",
    "        elif value > maximum: list_index = n_bins\n",
    "        else: list_index = int(floor((value-minimum)/bin_width))\n",
    "        histogram_list[list_index] += 1\n",
    "    return {\n",
    "        \"bin_width\":bin_width,\n",
<<<<<<< HEAD
    "        \"minimum\":minimum,\n",
    "        \"maximum\":maximum,\n",
=======
    "        \"min\":min,\n",
    "        \"max\":max,\n",
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
    "        \"n_bins\":n_bins,\n",
    "        \"bin_boundaries\":bin_boundaries,\n",
    "        \"histogram_list\":histogram_list\n",
    "    }\n",
    "\n",
    "\n",
    "def log_transform(value): #Resolve small numbers more precisely than large ones\n",
    "    return log(value)\n",
    "\n",
    "histogram = populate_histogram(test_floats, **hist_settings)\n",
    "print(histogram)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 69,
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "107\n",
      "82\n"
=======
      "106\n",
      "94\n"
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "def histogram_integral_approximate(threshold, bin_width, minimum, maximum, n_bins, bin_boundaries, histogram_list):\n",
    "    #Integrates from the threshold to infinity, including all values that share a bin with the threshold\n",
    "    if threshold < minimum: return sum(histogram_list)\n",
    "    if threshold > maximum: return 0\n",
    "    threshold_bin = int(floor((threshold-minimum)/bin_width))\n",
=======
    "def histogram_integral_approximate(threshold, bin_width, min, max, n_bins, bin_boundaries, histogram_list):\n",
    "    #Integrates from the threshold to infinity, including all values that share a bin with the threshold\n",
    "    if threshold < min: return 0\n",
    "    if threshold > max: return sum(histogram_list)\n",
    "    threshold_bin = int(floor((threshold-min)/bin_width))\n",
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
    "    total = 0\n",
    "    for i in range(threshold_bin, n_bins): total+=histogram_list[i]\n",
    "    return total\n",
    "\n",
<<<<<<< HEAD
    "def histogram_integral_precise(threshold, bin_width, minimum, maximum, n_bins, bin_boundaries, histogram_list):\n",
    "    #Integrates from the threshold to infinity, with linear interpolation within the bin that includes the threshold\n",
    "    if threshold < minimum: return 0\n",
    "    if threshold > maximum: return sum(histogram_list)\n",
    "    threshold_bin = int(floor((threshold-minimum)/bin_width))\n",
    "    total = int(round(histogram_list[threshold_bin] * (((threshold_bin+1)*bin_width-threshold - minimum)))) #Not sure why I have to force this to int - shouldn't it stay an int since items in histogram_list are ints?\n",
=======
    "def histogram_integral_precise(threshold, bin_width, min, max, n_bins, bin_boundaries, histogram_list):\n",
    "    #Integrates from the threshold to infinity, with linear interpolation within the bin that includes the threshold\n",
    "    if threshold < min: return 0\n",
    "    if threshold > max: return sum(histogram_list)\n",
    "    threshold_bin = int(floor((threshold-min)/bin_width))\n",
    "    total = int(round(histogram_list[threshold_bin] * ((threshold - min - threshold_bin*bin_width)/bin_width))) #Not sure why I have to force this to int - shouldn't it stay an int since items in histogram_list are ints?\n",
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
    "    for i in range(threshold_bin+1, n_bins): total += histogram_list[i]\n",
    "    return total\n",
    "\n",
    "threshold = 0.5\n",
    "print(histogram_integral_approximate(threshold, **histogram))\n",
    "print(histogram_integral_precise(threshold, **histogram))\n",
    "#approximate will always overestimate relative to precise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-oriented version\n",
    "\n",
<<<<<<< HEAD
    "This lays out the basic functionality, but to really see how this works it's better to see the data in the context provided by object-oriented code. Starting to lay that out using compact numpy arrays, with smart handling of transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, bring in some code for unit handling:"
=======
    "This lays out the basic functionality, but to really see how this works it's better to see the data in the context provided by object-oriented code. Starting to lay that out using compact numpy arrays. First, bring in some code for unit handling:"
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function smart_units takes a string (or number - which will be retruned unchanged as a float) and converts it into a float in internal units\n",
    "# internal units: meters, seconds, meters / second, cubic meters, radians for angles, celcius for temperatures, proportion (0 to 1) for proportions,\n",
    "# cubic meters per second for volumetric rate, I think that's it.\n",
    "\n",
<<<<<<< HEAD
=======
    "import sys\n",
    "\n",
    "\n",
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
    "#All these should be lower case\n",
    "m_names = ['m', 'meters', 'meter']\n",
    "km_names = ['km', 'kilometers', 'kilometer']\n",
    "mi_names = ['mi', 'miles', 'mile']\n",
    "NMi_names = ['nmi', 'nautical miles']\n",
    "ft_names = ['ft', 'feet', 'foot']\n",
    "in_names = ['in', 'inch', 'inches']\n",
    "ms_names = ['m/s', 'meters per second']\n",
    "mph_names = ['mph', 'miles per hour']\n",
    "knots_names = ['knots', 'knot', 'nautical miles per hour', 'kts']\n",
    "kph_names = ['kph', 'kilometers per hour', 'km/hr']\n",
    "s_names = ['s', 'seconds', 'second']\n",
    "min_names = ['min', 'minute', 'minutes']\n",
    "hour_names = ['hr', 'hrs', 'hour', 'hours']\n",
    "day_names = ['day','days']\n",
    "year_names = ['year','yr','years']\n",
    "c_names = ['c', 'celsius', '°c']\n",
    "f_names = ['f', 'fahrenheit', '°f']\n",
    "k_names = ['k', 'kelvin', '°k']\n",
    "prop_names = ['proportion','p','prop']\n",
    "percent_names = ['%','percent']\n",
    "m3_names = ['m^3', 'm3', 'cubic meters', 'cubic meter']\n",
    "l_names = ['l','liter','liters']\n",
    "oil_bbl_names = ['bbl','barrel','bbls','barrels']\n",
    "gal_names = ['gallons', 'gallon', 'gal']\n",
    "m3_per_second_names = ['m^3/s', 'm^3 / s', 'm3ps', 'cubic meters per second']\n",
    "liters_per_second_names = ['l/s','liters per second']\n",
    "gallons_per_minute_names = ['gal/min', 'gallons per minute', 'gpm']\n",
    "oil_barrels_per_hours_names = ['bbls/hr', 'bbl/hr', 'barrels per hour', 'bph']\n",
    "degree_names = ['degrees', '°', 'deg']\n",
    "radian_names = ['radians']\n",
    "\n",
    "zero = [0,0.0,'0','zero','ZERO','Zero','0.0']\n",
    "\n",
    "bad_chars = ' ,(){}[]\\t\\n' #To be stripped\n",
    "\n",
    "\n",
    "def smart_units(input_string, verbose = False):\n",
    "    try: return float(input_string) #If it's just a number, trust that it is what it's supposed to be.\n",
    "    except ValueError: pass\n",
    "    input_string.strip(bad_chars)\n",
    "    if not verbose and input_string in zero: return 0.0\n",
    "    elif input_string == 'infinite': return sys.float_info.max #maximum float value\n",
    "    else:\n",
    "        try: value, units = tuple(input_string.split(' ', 1))\n",
    "        except ValueError: raise NameError('Not a usable string for verbose smart_units - must include units:',input_string)\n",
    "        units.strip(bad_chars)\n",
    "        units = units.lower()\n",
    "        if verbose:\n",
    "            if units in m_names + ft_names + in_names + km_names + NMi_names + mi_names: return length_m(value, units), 'length', \"meters\"\n",
    "            elif units in ms_names + mph_names + knots_names + kph_names: return velocity_m_s(value, units), \"velocity\", \"meters per second\"\n",
    "            elif units in s_names + min_names + hour_names + day_names + year_names: return time_s(value, units), \"time\", \"seconds\"\n",
    "            elif units in m3_names + l_names + oil_bbl_names + gal_names: return volume_m3(value, units), \"volume\", \"cubic meters\"\n",
    "            elif units in c_names + f_names + k_names: return temperature(value, units), \"temperature\", \"Celsius\"\n",
    "            elif units in m3_per_second_names + liters_per_second_names + gallons_per_minute_names + oil_barrels_per_hours_names: return discharge_m3_s(value, units), \"discharge\", \"m^3/s\"\n",
    "            elif units in prop_names + percent_names: return proportion(value, units), \"proportion\", \"non-dimensional\"\n",
    "            elif units in degree_names + radian_names: return angle_rad(value, units), \"angle\", \"radians\"\n",
    "            else: raise NameError('Unknown text string for smart_units: {0}\\nNote that there has to be a space between the number and the unit, like \"5 °F\" not \"5°F\".'.format(input_string))\n",
    "        else:\n",
    "            if units in m_names + ft_names + in_names + km_names + NMi_names + mi_names: return length_m(value, units)\n",
    "            elif units in ms_names + mph_names + knots_names + kph_names: return velocity_m_s(value, units)\n",
    "            elif units in s_names + min_names + hour_names + day_names + year_names: return time_s(value, units)\n",
    "            elif units in m3_names + l_names + oil_bbl_names + gal_names: return volume_m3(value, units)\n",
    "            elif units in c_names + f_names + k_names: return temperature(value, units)\n",
    "            elif units in m3_per_second_names + liters_per_second_names + gallons_per_minute_names + oil_barrels_per_hours_names: return discharge_m3_s(value, units)\n",
    "            elif units in prop_names + percent_names: return proportion(value, units)\n",
    "            elif units in degree_names + radian_names: return angle_rad(value, units)\n",
    "            else: raise NameError('Unknown text string for smart_units: {0}\\nNote that there has to be a space between the number and the unit, like \"5 °F\" not \"5°F\".'.format(input_string))\n",
    "\n",
    "def length_m(value, units=None):\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        elif value in zero: return 0.0\n",
    "        value = float(value)\n",
    "    if units.lower() in m_names: return value\n",
    "    elif units.lower() in ft_names: return value * 0.3048\n",
    "    elif units.lower() in in_names: return value * 0.0254\n",
    "    elif units.lower() in km_names: return value * 1000\n",
    "    elif units.lower() in mi_names: return value * 1609.34\n",
    "    elif units.lower() in NMi_names: return value * 1852\n",
    "    else: raise NameError('Unknown length units '+units)\n",
    "\n",
    "def velocity_m_s(value, units=None):\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        elif value in zero: return 0.0\n",
    "        value = float(value)\n",
    "    if units.lower() in ms_names: return value\n",
    "    elif units.lower() in mph_names : return value * 0.44704\n",
    "    elif units.lower() in knots_names: return value * 0.514444444\n",
    "    elif units.lower() in kph_names: return value * 0.277778\n",
    "    else: raise NameError('Unknown velocity units '+units)\n",
    "\n",
    "def time_s(value, units=None): #returns a value in seconds\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        elif value in zero: return 0.0\n",
    "        value = float(value)\n",
    "    if units.lower() in s_names: return value\n",
    "    elif units.lower() in min_names: return 60.0 * value\n",
    "    elif units.lower() in hour_names: return 3600.0 * value\n",
    "    elif units.lower() in day_names: return 86400.0 * value\n",
    "    elif units.lower() in year_names: return 366.0*86400*value #assumes a leap-year, so this is maximum year-length rather than true year length\n",
    "    else: raise NameError('Unknown period units: '+units)\n",
    "\n",
    "def volume_m3(value, units=None):\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        elif value in zero: return 0.0\n",
    "        value = float(value)\n",
    "    if units.lower() in m3_names: return value\n",
    "    elif units.lower() in l_names: return value / 1000\n",
    "    elif units.lower() in oil_bbl_names: return value * .158987\n",
    "    elif units.lower() in gal_names: return value * .00378541\n",
    "    else: raise NameError('Unknown volume units: '+units)\n",
    "\n",
    "def discharge_m3_s(value, units=None):\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        elif value in zero: return 0.0\n",
    "        value = float(value)\n",
    "    if units.lower() in m3_per_second_names: return value\n",
    "    elif units.lower() in liters_per_second_names: return value / 1000\n",
    "    elif units.lower() in gallons_per_minute_names: return value * 0.0000630902\n",
    "    elif units.lower() in oil_barrels_per_hours_names: return value * 0.0000441631\n",
    "    else: raise NameError('Unknown discharge units: '+units)\n",
    "\n",
    "\n",
    "def temperature(value, units=None): #retunrs a value in celsius\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        value = float(value)\n",
    "    if units.lower() in c_names: return value\n",
    "    elif units.lower() in f_names: return (value - 32) / 1.8\n",
    "    elif units.lower() in k_names: return value - 273.15\n",
    "    else: raise NameError('Unknown temperature units: '+units)\n",
    "\n",
    "def proportion(value, units=None): #returns a non-dimensional value from zero to one\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        elif value in zero: return 0.0\n",
    "        value = float(value)\n",
    "    if units.lower() in prop_names: return value\n",
    "    elif units.lower() in percent_names: return value/100\n",
    "    else: raise NameError('Unknown proportion units: '+units)\n",
    "\n",
    "def angle_rad(value, units=None):\n",
    "    units.strip(bad_chars)\n",
    "    try: value = float(value)\n",
    "    except TypeError:\n",
    "        value.strip(bad_chars)\n",
    "        if value == 'infinite': return sys.float_info.max #maximum float value\n",
    "        elif value in zero: return 0.0\n",
    "        value = float(value)\n",
    "    if units.lower() in degree_names: return radians(value)\n",
    "    elif units.lower() in radian_names: return value\n",
    "    else: raise NameError('Unknown angle units: '+units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "First a function to generate some random test data for a week. Would be good to make this so it would generate different random distributions for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_central_variable_1_week(n = 168, how_extreme = 5):\n",
    "    return [sum([rand.random() for i in range(how_extreme)])/rand_reps for i in range(n)]\n",
    "\n",
    "def random_exponential_variable_1_week(n = 168, how_extreme = 5):\n",
    "    return [rand.random()**how_extreme for i in range(n)]\n",
    "\n",
    "def random_exponential_zero_common_1_week(n = 168, how_extreme = 5):\n",
    "    value_list = []\n",
    "    p_zero = 0.9\n",
    "    for i in range(n):\n",
    "        if rand.random() < p_zero: value_list.append(0.0)\n",
    "        else: value_list.append(rand.random()**how_extreme)\n",
    "    return value_list\n",
    "\n",
    "def rescale_random_0_1_to_range(value_list, minimum, maximum):\n",
    "    total_range = maximum-minimum\n",
    "    for i,value in enumerate(value_list):\n",
    "        value_list[i] = value*total_range + minimum\n",
    "    return value_list #Why do I have to return this?\n",
    "\n",
    "def make_weeks(n_weeks, rand_function, minimum_text, maximum_text, how_extreme = 5):\n",
    "    return [rescale_random_0_1_to_range(rand_function(168, how_extreme),smart_units(minimum_text),smart_units(maximum_text)) for i in range(n_weeks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions to transform data that's not well partitioned on a histogram with linearly distributed bins. Each function contains its own inverse."
=======
    "Now sketch out the structures and classes. These settings are \"real\" in that they might be meaningful for real data, though the data that's in this example is still random junk"
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "def identity(value, inverse=False): #Identity is its own inverse\n",
    "    return value\n",
    "\n",
    "def log_value(value, inverse=False):\n",
    "    if inverse: return e**value #By default log is the natural log, base e, which is provided by math\n",
    "    else: return log(value)\n",
    "\n",
    "def sqrt_value(value, inverse=False):\n",
    "    if inverse: return value*value\n",
    "    else: return sqrt(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A place for utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "def rescale_metric(metric_array):\n",
    "    minimum = min(metric_array)\n",
    "    maximum = max(metric_array)\n",
    "    raw_range = maximum-minimum\n",
    "    if raw_range > 0:\n",
    "        for i,value in enumerate(metric_array):\n",
    "            metric_array[i] = (value - minimum)/raw_range\n",
    "    else:\n",
    "        for i in range(len(metric_array)):\n",
    "            metric_array[i] = 0.0\n",
    "    #Array should be passed by reference - no return necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a set of functions that generate a metric from a specific histogram, with some given settings. All these are passed the same variables so that later we can call them knowing what they'll want, even if they don't use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric functions\n",
    "def count_is_above(histogram_list, minimum, maximum, n_bins, bin_width, threshold, transform = identity):\n",
    "    #Integrates from the threshold to infinity, with linear interpolation within the bin that includes the threshold\n",
    "    threshold = transform(threshold) #This means linear interpolation in the transformed space, which I think is good - maybe needs a little thinking\n",
    "    if threshold < minimum: return sum(histogram_list)\n",
    "    if threshold > maximum: return 0\n",
    "    threshold_bin = int(floor((threshold-minimum)/bin_width))\n",
    "    total = int(round(histogram_list[threshold_bin] * (((threshold_bin+1)*bin_width - threshold - minimum)/bin_width))) #Not sure why I have to force this to int - shouldn't it stay an int since items in histogram_list are ints?\n",
    "    for i in range(threshold_bin+1, n_bins): total += histogram_list[i]\n",
    "    return total\n",
    "\n",
    "def count_is_below(histogram_list, minimum, maximum, n_bins, bin_width, threshold, transform = identity):\n",
    "    #Integrates from the threshold to infinity, with linear interpolation within the bin that includes the threshold\n",
    "    threshold = transform(threshold)\n",
    "    if threshold < minimum: return 0\n",
    "    if threshold > maximum: return sum(histogram_list)\n",
    "    threshold_bin = int(floor((threshold-minimum)/bin_width))\n",
    "    total = int(round(histogram_list[threshold_bin] * ((threshold - minimum - threshold_bin*bin_width)/bin_width))) #Not sure why I have to force this to int - shouldn't it stay an int since items in histogram_list are ints?\n",
    "    for i in range(0, threshold_bin): total += histogram_list[i]\n",
    "    return total\n",
    "\n",
    "def median(histogram_list, minimum, maximum, n_bins, bin_width, threshold = None, transform = identity):\n",
    "    #Do all the math in the transformed space, then un-transform it when returning the result\n",
    "    total = sum(histogram_list)\n",
    "    median_rank = float(total)/2\n",
    "    partial_sum = 0\n",
    "    prev_partial_sum = 0\n",
    "    bin = 0\n",
    "    while partial_sum < median_rank:\n",
    "        prev_partial_sum = partial_sum\n",
    "        partial_sum += histogram_list[bin]\n",
    "        bin += 1\n",
    "    untransformed_median = bin_width * ((float(partial_sum) - median_rank)/(partial_sum - prev_partial_sum)+ bin - 1) - minimum\n",
    "    return transform(untransformed_median, inverse = True)\n",
    "\n",
    "def sum_up(histogram_list, minimum, maximum, n_bins, bin_width, threshold = None, transform = identity):\n",
    "    total = 0.0\n",
    "    current = minimum + bin_width/2\n",
    "    for i in range(n_bins):\n",
    "        total += transform(current, inverse=True) * histogram_list[i] #A subtlety here is that we assume the transformation is more than a convenience - it's a meaningful property of the system, reflecting how values are distributed between bin boundaries\n",
    "        i+=1\n",
    "        current += bin_width\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now settings - the variable settings are probably a universal constant, whereas the metric settings reflect a single user's preferences. In this case, they match the example wireframe I sketched out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "variable_settings = {\n",
    "    'wind'       :{'minimum':0,'maximum':'150 mph','bin_width':'5 mph'},\n",
    "    'gust'       :{'minimum':0,'maximum':'150 mph','bin_width':'5 mph'},\n",
    "    'temperature':{'minimum':'-50 C', 'maximum':'70 C', 'bin_width':'5 C'},\n",
    "    'dir'        :{'minimum':0, 'maximum':'360 degrees', 'bin_width':'10 degrees'},\n",
    "    'hvis'       :{'minimum':'5 meters', 'maximum':'100 miles', 'transform':log_value, 'n_bins':20}, #With log transform it seems better to define it based on the number of bins rather than the bin_width\n",
    "    'ceiling'    :{'minimum':'100 meters', 'maximum':'100 miles', 'transform':log_value, 'n_bins':20},\n",
    "    'cover'      :{'minimum':0, 'maximum':'100 %', 'bin_width':'10 %'},\n",
    "    'rain'       :{'minimum':0, 'maximum':'1 foot', 'transform':sqrt_value, 'n_bins':32}, #Ranges that extend to zero can't be transformed with log - use sqrt instead (but not for negative numbers)\n",
    "    'humidity'   :{'minimum':0, 'maximum':'100 %', 'bin_width':'5 %'}\n",
    "}\n",
    "\n",
    "#Ultimately need some code to ensure that the weights add to 1\n",
    "metric_settings = {\n",
    "    'temperature':{'function':count_is_above, 'threshold':'62 F', 'weight': 0.42},\n",
    "    'rain'       :{'function':sum_up, 'weight':0.2},\n",
    "    'cover'      :{'function':median, 'weight':0.38}\n",
    "}\n",
    "\n",
    "vis_settings = { #These should be between 0 and 1\n",
    "    'low_medium':0.08,\n",
    "    'medium_high':0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally make some classes for a single variable, and for an entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "class variable:\n",
    "    \n",
    "    def __init__(self, n_weeks=0, raw_values=None, minimum=0.0, maximum=sys.float_info.max, bin_width=None, transform=identity, n_bins=0):\n",
    "        if raw_values: self.n_weeks = len(raw_values) #n_weeks should only be populated if the intention is to initialize with no data\n",
    "        else: self.n_weeks = n_weeks\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_variable_1_week():\n",
    "    n = 168 #number of hours in a week\n",
    "    rand_reps = 5\n",
    "    return [sum([rand.random() for i in range(rand_reps)])/rand_reps for i in range(n)]\n",
    "\n",
    "#Transforms\n",
    "def identity(value):\n",
    "    return value\n",
    "\n",
    "def log_value(value):\n",
    "    return log(value)\n",
    "\n",
    "#Settings\n",
    "variable_settings = {\n",
    "    'wind'    :{'minimum':0,'maximum':'150 mph','bin_width':'5 mph'},\n",
    "    'gust'    :{'minimum':0,'maximum':'150 mph','bin_width':'5 mph'},\n",
    "    'temp'    :{'minimum':'-50 C', 'maximum':'70 C', 'bin_width':'5 C'},\n",
    "    'dir'     :{'minimum':0, 'maximum':'360 degrees', 'bin_width':'10 degrees'},\n",
    "    'hvis'    :{'minimum':'5 meters', 'maximum':'100 miles', 'transform':log_value, 'n_bins':20}, #With log transform it seems better to define it based on the number of bins rather than the bin_width\n",
    "    'ceiling' :{'minimum':'100 meters', 'maximum':'100 miles', 'transform':log_value, 'n_bins':20},\n",
    "    'rain'    :{'minimum':'0.0025 inches', 'maximum':'1 foot', 'transform':log_value, 'n_bins':32},\n",
    "    'humidity':{'minimum':0, 'maximum':'100 %', 'bin_width':'5 %'}\n",
    "}\n",
    "\n",
    "#Classes\n",
    "class variable:\n",
    "    \n",
    "    def __init__(self, n_weeks=0, raw_data=None, minimum=0.0, maximum=sys.float_info.max, bin_width=None, transform=identity, n_bins=0):\n",
    "        if raw_data: n_weeks = len(raw_data) #n_weeks should only be populated if the intention is to initialize with no data\n",
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
    "        self.transform = transform\n",
    "        self.minimum = transform(smart_units(minimum))\n",
    "        self.maximum = transform(smart_units(maximum))\n",
    "        if bin_width:\n",
    "            self.bin_width = transform(smart_units(bin_width)) #Generally you should only define bin width if you're using the identy transform, but just in case...\n",
<<<<<<< HEAD
    "            self.n_bins = int(ceil((self.maximum-self.minimum)/self.bin_width))\n",
    "        elif n_bins:\n",
    "            self.n_bins = n_bins\n",
    "            self.bin_width = (self.maximum-self.minimum)/n_bins\n",
    "        else:\n",
    "            raise Exception(\"No settings for either n_bins or bin_width, so the variable can't be initialized\")\n",
    "        self.bins = np.zeros((self.n_weeks,self.n_bins), dtype=np.uint8) #2D array, one row per week, one column per histogram bin\n",
    "        if raw_values: self.process_raw_data(raw_values)\n",
    "        \n",
    "    def process_raw_data(self, raw_values):\n",
    "        for i,week in enumerate(raw_values):\n",
    "            for value in week:\n",
    "                value = self.transform(value)\n",
    "                if value < self.minimum: list_index = 0\n",
    "                elif value > self.maximum: list_index = self.n_bins-1\n",
=======
    "            self.n_bins = int(ceil((maximum-minimum)/bin_width)))\n",
    "        elif n_bins:\n",
    "            self.n_bins = n_bins\n",
    "            self.bin_width = (self.maximum-self.minimum)/n_bins\n",
    "        else raise Exception(\"No settings for either n_bins or bin_width, so the variable can't be initialized\")\n",
    "        self.bins = np.zeros((n_weeks,self.n_bins), dtype=uint8) #2D array, one row per week, one column per histogram bin\n",
    "        if raw_data is not None: process_raw_data(raw_data)\n",
    "        \n",
    "    def process_raw_data(self, raw_data):\n",
    "        for i,week in enumerate(weeks):\n",
    "            for value in week:\n",
    "                value = self.transform(value)\n",
    "                if value < self.minimum: list_index = 0\n",
    "                elif value > self.maximum: list_index = self.n_bins\n",
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
    "                else: list_index = int(floor((value-self.minimum)/self.bin_width))\n",
    "                self.bins[i][list_index] += 1\n",
    "\n",
    "class station:\n",
    "    \n",
<<<<<<< HEAD
    "    def __init__(self, n_weeks, variable_settings, raw_data):\n",
    "        self.n_weeks = n_weeks\n",
    "        self.raw_data = raw_data\n",
    "        self.processed_data = dict([(name, variable(raw_values = raw_data[name], **settings)) for name,settings in variable_settings.items()])\n",
    "    \n",
    "    def generate_metric(self, metric_settings):\n",
    "        total_metric = np.zeros(self.n_weeks, dtype=np.float32)\n",
    "        for variable_name, settings in metric_settings.items():\n",
    "            data = self.processed_data[variable_name]\n",
    "            metric = np.zeros(self.n_weeks, dtype=np.float32)\n",
    "            for i,week in enumerate(self.processed_data[variable_name].bins):\n",
    "                if 'threshold' in settings: threshold = smart_units(settings['threshold'])\n",
    "                else: threshold = None\n",
    "                metric[i] = settings['function'](week, data.minimum, data.maximum, data.n_bins, data.bin_width, threshold, data.transform)\n",
    "            rescale_metric(metric) #Now the values range from 0.0 to 1.0. Scaled based on the whole station, but not applicable between stations.\n",
    "            for i in range(self.n_weeks):\n",
    "                total_metric[i] += metric[i] * settings['weight']\n",
    "        return total_metric\n",
    "    \n",
    "    def metric_to_3_cats(self, vis_settings, metric_settings=None, raw_metric=None):\n",
    "        if metric_settings: raw_metric = self.generate_metric(metric_settings)\n",
    "        elif raw_metric is None: raise Exception('Must send metric_to_3_cats either raw_metric or metric_settings')\n",
    "        vis_values = []\n",
    "        for value in raw_metric:\n",
    "            if value < vis_settings['low_medium']: vis_values.append('low')\n",
    "            elif value < vis_settings['medium_high']: vis_values.append('medium')\n",
    "            else: vis_values.append('high')\n",
    "        return vis_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it seem to work with some test-data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03573646 0.02021387 0.04015178 0.05912384 0.04587789 0.01234909\n",
      " 0.03884098 0.06740255 0.02794067 0.07036909 0.00206968 0.07699207\n",
      " 0.07837185 0.04794757 0.03359779 0.02538807 0.06402208 0.12459469\n",
      " 0.02525009 0.0522249  0.02531908 0.06008969 0.03456365 0.10313902\n",
      " 0.08078647 0.04753364 0.09527422 0.02669886 0.04732667 0.0567782\n",
      " 0.02600897 0.04401518 0.07830287 0.0787168  0.04284236 0.05664022\n",
      " 0.05953777 0.12011038 0.12169714 0.07009314 0.07388755 0.02690583\n",
      " 0.0832011  0.04663677 0.07492239 0.06760952 0.14508452 0.02573301\n",
      " 0.06691962 0.05091411 0.07181787 0.07719903 0.03932391 0.05325975\n",
      " 0.0864436  0.06036564 0.10362194 0.03297689 0.09141083 0.0367713\n",
      " 0.02456019 0.09644705 0.01945498 0.01752329 0.07823388 0.09458434\n",
      " 0.16654018 0.07988961 0.13107969 0.09520525 0.09479131 0.08692653\n",
      " 0.02876854 0.07761297 0.09768885 0.10755433 0.06236633 0.08271818\n",
      " 0.00462228 0.02311142 0.07499138 0.07464643 0.06974819 0.10831322\n",
      " 0.07719903 0.07181787 0.04208348 0.09334253 0.02849258 0.03904795\n",
      " 0.02511211 0.06457399 0.01759227 0.06340117 0.01138324 0.09872369\n",
      " 0.04608486 0.10286306 0.06850637 0.01379786 0.09389444 0.05201794\n",
      " 0.09430838 0.03697827 0.00958951 0.02117972 0.01655743 0.00758882\n",
      " 0.09279062 0.06284926 0.04049673 0.05181097 0.07775094 0.10569161\n",
      " 0.05967575 0.07002415 0.06484995 0.038703   0.02759572 0.08878924\n",
      " 0.01635047 0.05629528 0.03842705 0.05829597 0.05112107 0.08327009\n",
      " 0.05325975 0.04484305 0.06050362 0.05119007 0.01579855 0.02752674\n",
      " 0.03877199 0.02028286 0.10465678 0.04373922 0.01069334 0.02628493\n",
      " 0.2        0.02628493 0.0800276  0.04884443 0.07616419 0.05898585\n",
      " 0.01262504 0.02538807 0.04511901 0.06878234 0.09982753 0.00855467\n",
      " 0.04249742 0.00338048 0.04525699 0.02124871 0.08195929 0.09527422\n",
      " 0.02531908 0.05519145 0.01200414 0.01448776 0.1018972  0.02593998\n",
      " 0.03511556 0.03187306 0.04208348 0.08630562 0.08230424 0.04808555\n",
      " 0.03911694 0.04511901 0.02883753 0.12907898 0.01641946 0.08368403\n",
      " 0.02932046 0.02069679 0.04656779 0.03263194 0.07478441 0.08258019\n",
      " 0.06919627 0.04753364 0.03408072 0.04974129 0.07078303 0.09913763\n",
      " 0.07437047 0.06043463 0.06119351 0.04974129 0.05519145 0.0941704\n",
      " 0.02090376 0.04339428 0.02504312 0.04008279 0.02124871 0.07892377\n",
      " 0.05684719 0.08927216 0.06119351 0.03587444 0.006485   0.05077613\n",
      " 0.02090376 0.01600552 0.07285271 0.11328044 0.00538117 0.04222146\n",
      " 0.0638151  0.07768195 0.01296999 0.         0.01586754 0.02697482\n",
      " 0.08989307 0.04146257 0.02725078 0.0038634  0.05029321 0.02097275\n",
      " 0.08092446 0.04139359 0.06077958 0.03815109 0.04160056 0.00034495\n",
      " 0.09389444 0.16226286 0.02607796 0.03139014 0.02938945 0.01152121\n",
      " 0.1400483  0.05567437 0.0600207  0.05256986 0.0631942  0.0174543\n",
      " 0.00862366 0.0928596  0.0348396  0.03208003 0.04787858 0.04111763\n",
      " 0.01911004 0.04180752 0.0232494  0.02283546 0.04304933 0.01262504\n",
      " 0.08609866 0.02290445 0.05960676 0.03504657 0.02414626 0.07023111\n",
      " 0.05312177 0.05670921]\n",
      "['low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'medium', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'medium', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'medium', 'low', 'medium', 'low', 'low', 'medium', 'low', 'low', 'low', 'medium', 'high', 'low', 'medium', 'medium', 'medium', 'medium', 'low', 'low', 'medium', 'medium', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'medium', 'low', 'low', 'medium', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'high', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'medium', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'medium', 'medium', 'low', 'low', 'low', 'low', 'medium', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'high', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low']\n"
     ]
    }
   ],
   "source": [
    "#Test data\n",
    "n_weeks = 260 #5 years\n",
    "test_data = {\n",
    "    'wind'       :make_weeks(n_weeks, random_exponential_variable_1_week, 0, '150 mph', 10),\n",
    "    'gust'       :make_weeks(n_weeks, random_exponential_variable_1_week, 0, '150 mph', 7),\n",
    "    'temperature':make_weeks(n_weeks, random_central_variable_1_week, '-50 C', '70 C', 5),\n",
    "    'dir'        :make_weeks(n_weeks, random_central_variable_1_week, 0, '360 degrees', 1), \n",
    "    'hvis'       :make_weeks(n_weeks, random_central_variable_1_week, '5 m', '100 miles', 8),\n",
    "    'ceiling'    :make_weeks(n_weeks, random_central_variable_1_week, '100 m', '100 miles', 8),\n",
    "    'cover'      :make_weeks(n_weeks, random_central_variable_1_week, 0, '100 %', 1), \n",
    "    'rain'       :make_weeks(n_weeks, random_exponential_zero_common_1_week, 0, '1 foot', 10),\n",
    "    'humidity'   :make_weeks(n_weeks, random_central_variable_1_week, 0, '100 %', 3),\n",
    "}\n",
    "\n",
    "test_station = station(n_weeks, variable_settings, test_data)\n",
    "metric_test = test_station.generate_metric(metric_settings)\n",
    "metric_vis_test = test_station.metric_to_3_cats(vis_settings, raw_metric=metric_test)\n",
    "print(metric_test)\n",
    "print(metric_vis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
    "    def __init__(self, n_weeks, variable_settings):\n",
    "        self.n_weeks = n_weeks\n",
    "        raw_data = dict([(name,[random_variable_1_week() for j in range(n_weeks)]) for name in variable_settings.keys()]) #test code\n",
    "        for name,settings in variable_settings.iteritems():\n",
    "            processed_data = dict([(name, variable(raw_data=raw_data[name], **settings)) for i in range(n_variables)])\n",
    "    \n",
    "    def generate_metric(self, metric_component_dict):\n",
    "        metric = np.zeros(self.n_weeks, dtype=float32)\n",
    "        for variable, settings in metric_component_dict.iteritems():\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "        "
   ]
>>>>>>> 617cf570542a329560b25d93a63dfe7d0ccce621
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
