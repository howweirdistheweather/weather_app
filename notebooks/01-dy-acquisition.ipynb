{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HWTW Data Acquisition Notebook\n",
    "author(s):  David Yerrington (david@yerrington.net), Hig (hig314@gmail.com)\n",
    "\n",
    "\n",
    "This notebook will contain a clean process in which to import data in which we can use to prototype with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Loading\n",
    "\n",
    "Looks like our intial csv based on the \"short\" sample can be loaded simply with pandas without much trouble.  The data does appear to be somewhat improperly typed and the column headers can be updated from Hig's original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38214 entries, 0 to 38213\n",
      "Data columns (total 25 columns):\n",
      " % Relative Humidity      38214 non-null object\n",
      " Dew Point Temp           38214 non-null object\n",
      " Dry Bulb Temp            38214 non-null object\n",
      " Maintenance Indicator    38214 non-null object\n",
      " Precip. Total            38214 non-null object\n",
      " Pressure Tendency        38214 non-null object\n",
      " Record Type              38214 non-null object\n",
      " Sea Level Pressure       38214 non-null object\n",
      " Sky Conditions           38214 non-null object\n",
      " Station Pressure         38214 non-null object\n",
      " Station Type             38214 non-null object\n",
      " Time                     38214 non-null int64\n",
      " Val for Wind Char.       38214 non-null object\n",
      " Visibility               38214 non-null object\n",
      " Weather Type             38214 non-null object\n",
      " Wet Bulb Temp            38214 non-null object\n",
      " Wind Char. Gusts (kt)    38214 non-null object\n",
      " Wind Direction           38214 non-null object\n",
      " Wind Speed (kt)          38214 non-null object\n",
      " YearMonthDay             38214 non-null int64\n",
      "Wban Number               38214 non-null int64\n",
      "ceiling_ft                38204 non-null float64\n",
      "datetime                  38214 non-null object\n",
      "raw_sky_code              38214 non-null object\n",
      "vis_miles                 38208 non-null float64\n",
      "dtypes: float64(2), int64(3), object(20)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../data/external/25339_short.csv\", \n",
    "    low_memory            = False\n",
    ")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of the variable types are \"object\"\n",
    "We can't do much with \"object\" types so we need to convert them to `float64` or `int64` so we can do aggregation of any kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Cleaning\n",
    "\n",
    "#### Fix columns with leading spaced and special characters.\n",
    "\n",
    "For cleaning / mapping raw data for this source, we will use a basic class.  Once we get many different sources we can use a factory pattern to abstract this problem so our code is managable as it grows for more sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_data:\n",
    "    \n",
    "    verbose = False\n",
    "    \n",
    "    column_opts = dict(\n",
    "        remove_chars = [\"%\", \"(\", \")\", \".\"]\n",
    "    )\n",
    "    \n",
    "    df = False\n",
    "    \n",
    "    def __init__(self, **opts):\n",
    "        for attr, value in opts.items():\n",
    "            if hasattr(self, attr):\n",
    "                setattr(self, attr, value)\n",
    "    \n",
    "    def strip_characters(self, name):\n",
    "        for char in self.column_opts['remove_chars']:\n",
    "            name = name.replace(char, \"\")\n",
    "        return name\n",
    "    \n",
    "    def clean_columns(self):\n",
    "        df.columns = [\n",
    "            self.strip_characters(col).lower().strip().replace(\" \", \"_\") \n",
    "            for col in self.df.columns\n",
    "        ]\n",
    "\n",
    "    def clean(self):\n",
    "        self.clean_columns()\n",
    "        \n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "cleaner = clean_data(df = df)\n",
    "cleaner.clean()\n",
    "clean_df = cleaner.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert \"-\" which presumable are \"unknown\" to proper type \"NaN\"\n",
    "> Will push these fixes back to the class so we can run all these transformations after we've handled all the cases we want to clean for our ETL job.  This will make it easy to automate future sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.replace(r'-', np.nan, inplace = True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = [\n",
    "    'record_type', \n",
    "    'sky_conditions', \n",
    "    'station_type', \n",
    "    'visibility', \n",
    "    'weather_type', \n",
    "    'raw_sky_code', \n",
    "    'precip_total',       # has \"T\" strings as some values\n",
    "    'wind_char_gusts_kt', # has \"G\" strings as some values\n",
    "    'wind_direction'    \n",
    "]\n",
    "object_columns = [\n",
    "    name for name, dtype in clean_df.dtypes.items() \n",
    "    if dtype == \"object\" and name not in exclude_columns\n",
    "]\n",
    "clean_df[object_columns] = clean_df[object_columns].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have much more usable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38214 entries, 0 to 38213\n",
      "Data columns (total 25 columns):\n",
      "relative_humidity        20385 non-null float64\n",
      "dew_point_temp           19891 non-null float64\n",
      "dry_bulb_temp            20338 non-null float64\n",
      "maintenance_indicator    0 non-null float64\n",
      "precip_total             8367 non-null object\n",
      "pressure_tendency        6779 non-null float64\n",
      "record_type              38214 non-null object\n",
      "sea_level_pressure       20391 non-null float64\n",
      "sky_conditions           38204 non-null object\n",
      "station_pressure         20395 non-null float64\n",
      "station_type             38130 non-null object\n",
      "time                     38214 non-null int64\n",
      "val_for_wind_char        38211 non-null float64\n",
      "visibility               38208 non-null object\n",
      "weather_type             6307 non-null object\n",
      "wet_bulb_temp            20310 non-null float64\n",
      "wind_char_gusts_kt       5433 non-null object\n",
      "wind_direction           38211 non-null object\n",
      "wind_speed_kt            38211 non-null float64\n",
      "yearmonthday             38214 non-null int64\n",
      "wban_number              38214 non-null int64\n",
      "ceiling_ft               38204 non-null float64\n",
      "datetime                 0 non-null float64\n",
      "raw_sky_code             38204 non-null object\n",
      "vis_miles                38208 non-null float64\n",
      "dtypes: float64(13), int64(3), object(9)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still need timeseries type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['yearmonthday'] = pd.to_datetime(clean_df['yearmonthday'], format = \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More cleaning necessary\n",
    "\n",
    "I'll hold off until we've had a chance to talk more.\n",
    "\n",
    "- Mapping of column names\n",
    "- Proper typing of datetime\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset 1.0\n",
    "\n",
    "- Still need to come up with schema for a common format for all weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"../data/processed/25339_short_cleaned.csv\", encoding = \"UTF8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
